{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f4b6892-709b-4ba8-8b91-7314bf187e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from txtai.pipeline import Summary\n",
    "from transformers import pipeline\n",
    "from PyPDF2 import PdfReader\n",
    "from rake_nltk import Rake\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f86ffad-1888-4fa2-b0a5-39ae79e0ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def summary_text(text):\n",
    "    summary = Summary()\n",
    "    result = summary(text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afdc8432-0c63-41a8-afe5-f13e57825302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "def sentiment_analysis(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity, analysis.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1f61ade-618c-4d55-8df0-e37e7a58118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PdfReader(f)\n",
    "        page = reader.pages[0]  \n",
    "        text = page.extract_text()  # Extract the text from the page\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6719303b-5c9c-4149-95d2-54a9dbbf7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove extra spaces and non-alphabetic characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Replace multiple spaces with a single space\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def generate_meaningful_topic(text, num_words=3):\n",
    "    # Clean the input text\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Initialize CountVectorizer with word-level tokenization\n",
    "    vectorizer = CountVectorizer(stop_words='english', analyzer='word')\n",
    "    doc_term_matrix = vectorizer.fit_transform([text])\n",
    "    \n",
    "    # Apply LDA for topic extraction\n",
    "    lda_model = LatentDirichletAllocation(n_components=1, random_state=42)\n",
    "    lda_model.fit(doc_term_matrix)\n",
    "    \n",
    "    # Extract the top `num_words` words from the topic\n",
    "    words = [vectorizer.get_feature_names_out()[i] for i in lda_model.components_[0].argsort()[-num_words:]]\n",
    "    \n",
    "    # Combine the words into a single string for a meaningful topic\n",
    "    meaningful_topic = \" \".join(words).capitalize()\n",
    "    \n",
    "    return meaningful_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db613d87-29ea-42b6-a93c-8733b66cd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_page_config(layout=\"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57bbdede-cc94-458a-9f31-36fb10367e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = st.sidebar.selectbox(\"Select your choice\", [\"Summarize Text\", \"Summarize Document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0dfba48-14e2-474f-a6fb-1d632cfb3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract top N keywords using RAKE\n",
    "def extract_top_keywords(text, top_n=5):\n",
    "    r = Rake()  # Initialize RAKE (Rapid Automatic Keyword Extraction)\n",
    "    r.extract_keywords_from_text(text)\n",
    "    ranked_phrases = r.get_ranked_phrases_with_scores()  # Get ranked phrases with their scores\n",
    "    # Sort by score and take top N keywords\n",
    "    top_keywords = sorted(ranked_phrases, key=lambda x: x[0], reverse=True)[:top_n]\n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41a37bb0-2f85-458c-a9be-5fa55bc76aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Summarize Text option\n",
    "if choice == \"Summarize Text\":\n",
    "    st.subheader(\"Summarize, Extract Keywords, and Analyze Sentiment\")\n",
    "    input_text = st.text_area(\"Enter your text here\")\n",
    "    \n",
    "    if input_text:\n",
    "        if st.button(\"Process Text\"):\n",
    "            col1, col2, col3 = st.columns([1, 1, 1])  # Only three columns\n",
    "            \n",
    "            with col1:\n",
    "                st.markdown(\"**Your Input Text**\")\n",
    "                st.info(input_text, icon=\"ℹ️\")\n",
    "            \n",
    "            # Summarization\n",
    "            with col2:\n",
    "                st.markdown(\"**Summarized Text**\")\n",
    "                summarized_result = summary_text(input_text)\n",
    "                st.success(summarized_result)\n",
    "\n",
    "            # Extract top keywords\n",
    "            with col2:\n",
    "                st.markdown(\"**Top Extracted Keywords**\")\n",
    "                top_keywords = extract_top_keywords(summarized_result, top_n=5)\n",
    "                # Show keywords with their scores\n",
    "                for score, phrase in top_keywords:\n",
    "                    st.write(f\"{phrase} (Score: {score})\")\n",
    "\n",
    "            # Sentiment Analysis\n",
    "            with col3:\n",
    "                st.markdown(\"**Sentiment Analysis**\")\n",
    "                polarity, subjectivity = sentiment_analysis(input_text)\n",
    "                st.write(f\"Polarity: {polarity}, Subjectivity: {subjectivity}\")\n",
    "\n",
    "            # Topic Modeling (Move to a separate section below)\n",
    "            st.markdown(\"**Extracted Topics**\")\n",
    "            topics = generate_meaningful_topic(summarized_result)\n",
    "            st.success(\" \".join(topics))\n",
    "\n",
    "# Summarize Document option\n",
    "elif choice == \"Summarize Document\":\n",
    "    st.subheader(\"Summarize Document, Extract Keywords, and Analyze Sentiment\")\n",
    "    input_file = st.file_uploader(\"Upload your document\", type=[\"pdf\"])\n",
    "    \n",
    "    if input_file:\n",
    "        if st.button(\"Process Document\"):\n",
    "            with open(\"doc_file.pdf\", 'wb') as f:\n",
    "                f.write(input_file.getbuffer())  # Save the uploaded PDF to a local file\n",
    "            \n",
    "            col1, col2, col3 = st.columns([1, 1, 1])  # Only three columns\n",
    "            \n",
    "            with col1:\n",
    "                st.markdown(\"**Extracted Text from Document**\")\n",
    "                extracted_text = extract_text_from_pdf(\"doc_file.pdf\")  # Extract text from the uploaded PDF\n",
    "                st.info(extracted_text)\n",
    "            \n",
    "            # Summarization\n",
    "            with col2:\n",
    "                st.markdown(\"**Summarized Text**\")\n",
    "                summarized_result = summary_text(extracted_text)  # Summarize the extracted text\n",
    "                st.success(summarized_result)\n",
    "            \n",
    "            # Keyword Extraction\n",
    "            with col2:\n",
    "                st.markdown(\"**Top Extracted Keywords**\")\n",
    "                top_keywords = extract_top_keywords(summarized_result, top_n=5)\n",
    "                # Show keywords with their scores\n",
    "                for score, phrase in top_keywords:\n",
    "                    st.write(f\"{phrase} (Score: {score})\")\n",
    "\n",
    "            \n",
    "            # Sentiment Analysis\n",
    "            with col3:\n",
    "                st.markdown(\"**Sentiment Analysis**\")\n",
    "                polarity, subjectivity = sentiment_analysis(extracted_text)\n",
    "                st.write(f\"Polarity: {polarity}\\nSubjectivity: {subjectivity}\")\n",
    "\n",
    "            # Topic Modeling (Move to a separate section below)\n",
    "            st.markdown(\"**Extracted Topics**\")\n",
    "            topics = generate_meaningful_topic(summarized_result)\n",
    "            st.success(\" \".join(topics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70daf88-aa74-4b02-ac7d-53857fc59313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c60ef9-7548-4a11-8303-b5bd6dd8d48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
